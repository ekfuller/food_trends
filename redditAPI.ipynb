{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "f46753ca-ec57-4e8b-9634-bb80ddd56f75",
   "metadata": {},
   "outputs": [],
   "source": [
    "import requests\n",
    "import pandas as pd\n",
    "import time\n",
    "import datetime as dt"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "fb062d05-e083-4081-9a63-3487b8827c5c",
   "metadata": {},
   "outputs": [
    {
     "ename": "SyntaxError",
     "evalue": "invalid syntax (1264959224.py, line 1)",
     "output_type": "error",
     "traceback": [
      "\u001b[0;36m  File \u001b[0;32m\"/var/folders/5x/x41g3czd3g7d18145p3cfc9r0000gn/T/ipykernel_75309/1264959224.py\"\u001b[0;36m, line \u001b[0;32m1\u001b[0m\n\u001b[0;31m    reddit@reddit-VirtualBox:~$ curl -X POST -d 'grant_type=password&username=ekfuller&password=capstone22' --user 'yEQokwxZEpfab7-hjZGYqQ' https://www.reddit.com/api/v1/access_token\u001b[0m\n\u001b[0m                              ^\u001b[0m\n\u001b[0;31mSyntaxError\u001b[0m\u001b[0;31m:\u001b[0m invalid syntax\n"
     ]
    }
   ],
   "source": [
    "reddit@reddit-VirtualBox:~$ curl -X POST -d 'grant_type=password&username=ekfuller&password=capstone22' --user 'yEQokwxZEpfab7-hjZGYqQ' https://www.reddit.com/api/v1/access_token\n",
    "{\n",
    "    \"access_token\": \"0wfgItj8y8K12zwbKGBWEQantbeK8A\", \n",
    "    \"expires_in\": 3600, \n",
    "    \"scope\": \"*\", \n",
    "    \"token_type\": \"bearer\"\n",
    "}"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "25017be3-0a63-4137-910e-57de41114690",
   "metadata": {},
   "outputs": [],
   "source": [
    "{\"access_token\": \"1599096803386-pXyCtpw7RTrf9tle-o6JELcFLQa08Q\", \"token_type\": \"bearer\", \"expires_in\": 86400, \"scope\": \"*\"}"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "dfc65868-1f5c-4358-802b-f6c25cf43d6d",
   "metadata": {},
   "outputs": [],
   "source": [
    "curl -H \"Authorization: bearer 1599096803386-pXyCtpw7RTrf9tle-o6JELcFLQa08Q\" -A \"ChangeMeClient/0.1 by ekfuller\" https://oauth.reddit.com/api/v1/me\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "21c9fd7b-7ffc-46f5-975c-70e17b3f1e77",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Collecting praw\n",
      "  Downloading praw-7.6.0-py3-none-any.whl (188 kB)\n",
      "\u001b[K     |â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 188 kB 6.4 MB/s eta 0:00:01\n",
      "\u001b[?25hCollecting update-checker>=0.18\n",
      "  Downloading update_checker-0.18.0-py3-none-any.whl (7.0 kB)\n",
      "Collecting websocket-client>=0.54.0\n",
      "  Using cached websocket_client-1.3.2-py3-none-any.whl (54 kB)\n",
      "Collecting prawcore<3,>=2.1\n",
      "  Downloading prawcore-2.3.0-py3-none-any.whl (16 kB)\n",
      "Requirement already satisfied: requests<3.0,>=2.6.0 in /Users/emilyfuller/opt/anaconda3/lib/python3.9/site-packages (from prawcore<3,>=2.1->praw) (2.27.1)\n",
      "Requirement already satisfied: charset-normalizer~=2.0.0 in /Users/emilyfuller/opt/anaconda3/lib/python3.9/site-packages (from requests<3.0,>=2.6.0->prawcore<3,>=2.1->praw) (2.0.4)\n",
      "Requirement already satisfied: certifi>=2017.4.17 in /Users/emilyfuller/opt/anaconda3/lib/python3.9/site-packages (from requests<3.0,>=2.6.0->prawcore<3,>=2.1->praw) (2021.10.8)\n",
      "Requirement already satisfied: urllib3<1.27,>=1.21.1 in /Users/emilyfuller/opt/anaconda3/lib/python3.9/site-packages (from requests<3.0,>=2.6.0->prawcore<3,>=2.1->praw) (1.26.7)\n",
      "Requirement already satisfied: idna<4,>=2.5 in /Users/emilyfuller/opt/anaconda3/lib/python3.9/site-packages (from requests<3.0,>=2.6.0->prawcore<3,>=2.1->praw) (3.2)\n",
      "Installing collected packages: websocket-client, update-checker, prawcore, praw\n",
      "Successfully installed praw-7.6.0 prawcore-2.3.0 update-checker-0.18.0 websocket-client-1.3.2\n",
      "Note: you may need to restart the kernel to use updated packages.\n"
     ]
    }
   ],
   "source": [
    "pip install praw"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "90974033-2e94-45df-8b4c-d92ebf0d13fb",
   "metadata": {},
   "outputs": [],
   "source": [
    "import praw\n",
    "\n",
    "reddit = praw.Reddit(\n",
    "    client_id=\"yEQokwxZEpfab7-hjZGYqQ\",\n",
    "    client_secret=\"0wfgItj8y8K12zwbKGBWEQantbeK8A\",\n",
    "    password=\"capstone22\",\n",
    "    user_agent=\"food trends 2 by u/ekfuller\",\n",
    "    username=\"ekfuller\",\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "ba942a7e-a74c-4b2e-b35d-fb6b2d4998f7",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "v7n7ws 787 31\n",
      "v77t9b 24382 505\n",
      "v7d9sn 3284 111\n",
      "v7o9bx 134 11\n",
      "v6z5n8 6366 135\n",
      "v7kyrj 161 1\n",
      "v7nzeu 67 3\n",
      "v77b9z 805 25\n",
      "v7ce86 395 18\n",
      "v7qr9k 30 0\n",
      "v7oa6n 40 2\n",
      "v7jt36 99 9\n",
      "v7h73w 158 10\n",
      "v6zo18 1568 64\n",
      "v7qb75 26 5\n",
      "v7pz32 27 2\n",
      "v7mvjn 37 2\n",
      "v7opgi 27 0\n",
      "v7j1sl 83 6\n",
      "v7obf9 24 3\n",
      "v7ddqn 178 11\n",
      "v7q7ju 17 4\n",
      "v7rgz6 14 6\n",
      "v7rcgg 14 0\n",
      "v7oqb3 21 5\n"
     ]
    }
   ],
   "source": [
    "for submission in reddit.subreddit(\"food\").hot(limit=25):\n",
    "    print(submission.id, submission.score, submission.num_comments)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "cd366b7e-7137-4675-b0a6-dae158a4ceaa",
   "metadata": {},
   "outputs": [],
   "source": [
    "for submission in reddit.subreddit(\"food\").hot():\n",
    "    print(submission.id, submission.score)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "id": "645495ce-ac5c-4317-9153-9f6189969957",
   "metadata": {},
   "outputs": [],
   "source": [
    "post_ids_sample = ['v2waom','v68qlh','r8dsud', 'r8dw7i']"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 88,
   "id": "2efd94b8-872c-4867-8edb-552f7a284974",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "v2waom 18\n",
      "v68qlh 18\n",
      "r8dsud 18\n",
      "r8dw7i 18\n"
     ]
    }
   ],
   "source": [
    "for submission.id in post_ids:\n",
    "    print (submission.id, submission.score)\n",
    "    "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "id": "2ff8b43e-6547-4758-963a-6f320c45b6ed",
   "metadata": {},
   "outputs": [],
   "source": [
    "#old do not use\n",
    "def get_scores(posts):\n",
    "    ids =[]\n",
    "    scores =[]\n",
    "    comments = []\n",
    "    for submission in posts:\n",
    "        ids.append(reddit.submission('submission').id)\n",
    "        scores.append(reddit.submission('submission').score)\n",
    "        comments.append(reddit.submission('submission').num_comments)\n",
    "    return ids, scores, comments"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 104,
   "id": "d69ae342-0724-46d5-bf8a-58b89b3323ce",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(['v2waom', 'v68qlh', 'r8dsud', 'r8dw7i'], [82, 1, 1, 16], [7, 0, 1, 1])"
      ]
     },
     "execution_count": 104,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "get_scores(post_ids_sample)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 103,
   "id": "14dddd3a-c690-451d-861e-50e6e061ad5b",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "['v2waom', 'v68qlh', 'r8dsud', 'r8dw7i'] 1\n"
     ]
    }
   ],
   "source": [
    "print(post_ids_sample, reddit.submission(post_ids_sample[2]).score)\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "id": "fbcdb525-34a0-4e5f-b6b7-6b44d7cfddd7",
   "metadata": {},
   "outputs": [],
   "source": [
    "ids =[]\n",
    "scores =[]\n",
    "comments = []\n",
    "def get_scores(posts):\n",
    "    for submission in range(0,len(posts)):\n",
    "        ids.append(posts[submission])\n",
    "        scores.append(reddit.submission(posts[submission]).score)\n",
    "        comments.append(reddit.submission(posts[submission]).num_comments)\n",
    "    return ids, scores, comments"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "id": "d3d3c69a-b49a-4672-b13d-9d4c59776e4f",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(['v2waom', 'v68qlh', 'r8dsud', 'r8dw7i'], [81, 1, 1, 18], [7, 0, 1, 1])"
      ]
     },
     "execution_count": 11,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "get_scores(post_ids_sample)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "id": "c60df67b-22b2-4d7b-9845-78b95236acf9",
   "metadata": {},
   "outputs": [],
   "source": [
    "score_df_sample = pd.DataFrame([ids, scores, comments]).T"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "id": "d873ac31-3f27-47ba-9808-ff36a014e292",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>id</th>\n",
       "      <th>score</th>\n",
       "      <th>comments</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>v2waom</td>\n",
       "      <td>82</td>\n",
       "      <td>7</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>v68qlh</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>r8dsud</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>r8dw7i</td>\n",
       "      <td>16</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "       id score comments\n",
       "0  v2waom    82        7\n",
       "1  v68qlh     1        0\n",
       "2  r8dsud     1        1\n",
       "3  r8dw7i    16        1"
      ]
     },
     "execution_count": 11,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "score_df_sample.rename(columns={0:'id', 1:'score', 2:'comments'}, inplace=True)\n",
    "score_df_sample"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "4a065d42-3d7d-409f-a8ca-87975eff87d5",
   "metadata": {},
   "source": [
    "# read in reddit data from csv to get post ids"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "id": "ccb97cdf-d937-4d32-a28b-9a8b1cd1a0f2",
   "metadata": {},
   "outputs": [],
   "source": [
    "posts_df = pd.read_csv('../food_trends/Data/reddit_6_months.csv')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "id": "d0e324f2-3225-4060-8dff-607c554c5feb",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>id</th>\n",
       "      <th>subreddit</th>\n",
       "      <th>title</th>\n",
       "      <th>selftext</th>\n",
       "      <th>created_utc</th>\n",
       "      <th>num_comments</th>\n",
       "      <th>score</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>uu6g0w</td>\n",
       "      <td>food</td>\n",
       "      <td>[homemade] Polynesian (Chick-Fil-A sauce) chic...</td>\n",
       "      <td>NaN</td>\n",
       "      <td>1653077037</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>uu6cni</td>\n",
       "      <td>food</td>\n",
       "      <td>[I ate] Scotch mutton pie, pub in Edinburgh</td>\n",
       "      <td>NaN</td>\n",
       "      <td>1653076799</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "       id subreddit                                              title  \\\n",
       "0  uu6g0w      food  [homemade] Polynesian (Chick-Fil-A sauce) chic...   \n",
       "1  uu6cni      food        [I ate] Scotch mutton pie, pub in Edinburgh   \n",
       "\n",
       "  selftext  created_utc  num_comments  score  \n",
       "0      NaN   1653077037             0      1  \n",
       "1      NaN   1653076799             0      1  "
      ]
     },
     "execution_count": 13,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "posts_df.head(2)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "id": "c6f18b7b-dc8f-4d85-a4f0-5bea4d21e087",
   "metadata": {},
   "outputs": [],
   "source": [
    "posts_df.drop(columns=['subreddit','selftext', 'num_comments','score'], inplace=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "id": "ddf60b1d-d804-410a-b6bb-cfba8e1e847a",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>id</th>\n",
       "      <th>title</th>\n",
       "      <th>created_utc</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>uu6g0w</td>\n",
       "      <td>[homemade] Polynesian (Chick-Fil-A sauce) chic...</td>\n",
       "      <td>1653077037</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>uu6cni</td>\n",
       "      <td>[I ate] Scotch mutton pie, pub in Edinburgh</td>\n",
       "      <td>1653076799</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>uu6apo</td>\n",
       "      <td>[homemade] ðŸ‡²ðŸ‡¦</td>\n",
       "      <td>1653076639</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>uu644e</td>\n",
       "      <td>[homemade] Chilli Paneer, Spinach, Potatoes wi...</td>\n",
       "      <td>1653076091</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>uu5x2y</td>\n",
       "      <td>[Homemade] Tart - Salmon, spinach and goat cheese</td>\n",
       "      <td>1653075500</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>...</th>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>50172</th>\n",
       "      <td>r8dw7i</td>\n",
       "      <td>[homemade] Korean beef lettuce wraps</td>\n",
       "      <td>1638580177</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>50173</th>\n",
       "      <td>r8du3q</td>\n",
       "      <td>[homemade] Ramen. Inexperienced cook and Iâ€™m p...</td>\n",
       "      <td>1638580002</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>50174</th>\n",
       "      <td>r8dsud</td>\n",
       "      <td>[homemade] I am a very inexperienced cook and ...</td>\n",
       "      <td>1638579895</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>50175</th>\n",
       "      <td>r8dquz</td>\n",
       "      <td>[Homemade] Beef stew w/ fresh baked bread</td>\n",
       "      <td>1638579723</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>50176</th>\n",
       "      <td>r8dmi8</td>\n",
       "      <td>[homemade] thanksgiving leftover turkey and bi...</td>\n",
       "      <td>1638579365</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "<p>50177 rows Ã— 3 columns</p>\n",
       "</div>"
      ],
      "text/plain": [
       "           id                                              title  created_utc\n",
       "0      uu6g0w  [homemade] Polynesian (Chick-Fil-A sauce) chic...   1653077037\n",
       "1      uu6cni        [I ate] Scotch mutton pie, pub in Edinburgh   1653076799\n",
       "2      uu6apo                                      [homemade] ðŸ‡²ðŸ‡¦   1653076639\n",
       "3      uu644e  [homemade] Chilli Paneer, Spinach, Potatoes wi...   1653076091\n",
       "4      uu5x2y  [Homemade] Tart - Salmon, spinach and goat cheese   1653075500\n",
       "...       ...                                                ...          ...\n",
       "50172  r8dw7i               [homemade] Korean beef lettuce wraps   1638580177\n",
       "50173  r8du3q  [homemade] Ramen. Inexperienced cook and Iâ€™m p...   1638580002\n",
       "50174  r8dsud  [homemade] I am a very inexperienced cook and ...   1638579895\n",
       "50175  r8dquz          [Homemade] Beef stew w/ fresh baked bread   1638579723\n",
       "50176  r8dmi8  [homemade] thanksgiving leftover turkey and bi...   1638579365\n",
       "\n",
       "[50177 rows x 3 columns]"
      ]
     },
     "execution_count": 7,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "posts_df"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 42,
   "id": "89c65093-ddbd-4dbc-94a3-81791bfc3131",
   "metadata": {},
   "outputs": [],
   "source": [
    "increments_test = get_lists(chunks)[:4] #used to test the functions"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "id": "fd0ef707-93c6-4e3d-9017-675e35a3d340",
   "metadata": {},
   "outputs": [],
   "source": [
    "def get_scores(posts):\n",
    "    for submission in range(0,len(posts)):\n",
    "            ids.append(posts[submission])\n",
    "            scores.append(reddit.submission(posts[submission]).score)\n",
    "            comments.append(reddit.submission(posts[submission]).num_comments)\n",
    "    return posts"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "id": "4d5d0f17-05d7-4e40-a17a-22c8b4fcae4a",
   "metadata": {},
   "outputs": [],
   "source": [
    "def get_lists(chunks):\n",
    "    list_of_chunks = []\n",
    "    for x in range(0,len(chunks)):\n",
    "        list_of_chunks.append(list(chunks[x]))\n",
    "    return list_of_chunks"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "id": "01ce28d3-afc8-48b9-adae-0406d4803ffd",
   "metadata": {},
   "outputs": [],
   "source": [
    "ids = []\n",
    "scores = []\n",
    "comments = []\n",
    "def get_posts(items):\n",
    "    for i in range(0, len(items)):\n",
    "        posts = items[i]\n",
    "        for submission in range(0,len(posts)):\n",
    "            ids.append(posts[submission])\n",
    "            scores.append(reddit.submission(posts[submission]).score)\n",
    "            comments.append(reddit.submission(posts[submission]).num_comments)\n",
    "    return ids, scores, comments"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 48,
   "id": "8f0dec20-52f4-4e79-8612-4b674c85f32c",
   "metadata": {},
   "outputs": [],
   "source": [
    "posts_df_10 = posts_df[:1000]\n",
    "\n",
    "chunks = [posts_df_10['id'][x:x+100] for x in range(0, len(posts_df_10), 100)]\n",
    "\n",
    "increments_10 = get_lists(chunks)\n",
    "\n",
    "get_posts(increments_10)\n",
    "\n",
    "scores_df_10 = pd.DataFrame([ids, scores, comments]).T\n",
    "\n",
    "scores_df_10.rename(columns={0:'id', 1:'score', 2:'comments'}, inplace=True)\n",
    "scores_df_10.to_csv('./Data/0_to_10k_scores.csv', index=False)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "id": "e4793503-62f6-4a57-86ca-bcbfeb704f33",
   "metadata": {},
   "outputs": [],
   "source": [
    "posts_df_20 = posts_df[1000:2000]\n",
    "\n",
    "chunks = [posts_df_20['id'][x:x+100] for x in range(0, len(posts_df_20), 100)]\n",
    "\n",
    "increments_20 = get_lists(chunks)\n",
    "\n",
    "get_posts(increments_20)\n",
    "\n",
    "scores_df_20 = pd.DataFrame([ids, scores, comments]).T\n",
    "\n",
    "scores_df_20.rename(columns={0:'id', 1:'score', 2:'comments'}, inplace=True)\n",
    "scores_df_20\n",
    "\n",
    "scores_df_20.to_csv('./Data/10_to_20k_scores.csv', index=False)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 48,
   "id": "b5c1b91a-4e10-4299-83aa-640f9176101e",
   "metadata": {},
   "outputs": [],
   "source": [
    "ids = []\n",
    "scores = []\n",
    "comments = []\n",
    "def get_posts(items):\n",
    "    for i in range(0, len(items)):\n",
    "        posts = items[i]\n",
    "        for submission in range(0,len(posts)):\n",
    "            ids.append(posts[submission])\n",
    "            scores.append(reddit.submission(posts[submission]).score)\n",
    "            comments.append(reddit.submission(posts[submission]).num_comments)\n",
    "    return ids, scores, comments"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 49,
   "id": "16a812fc-7714-43dd-b0df-b934ee988d97",
   "metadata": {
    "scrolled": true,
    "tags": []
   },
   "outputs": [],
   "source": [
    "posts_df_30 = posts_df[2000:3000]\n",
    "\n",
    "chunks = [posts_df_30['id'][x:x+100] for x in range(0, len(posts_df_30), 100)]\n",
    "\n",
    "increments_30 = get_lists(chunks)\n",
    "\n",
    "get_posts(increments_30)\n",
    "\n",
    "scores_df_30 = pd.DataFrame([ids, scores, comments]).T\n",
    "\n",
    "scores_df_30.rename(columns={0:'id', 1:'score', 2:'comments'}, inplace=True)\n",
    "scores_df_30.to_csv('./Data/2_to_3k_scores.csv', index=False)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 23,
   "id": "6aa2a0d5-1922-489e-9ba1-8a7d05009a88",
   "metadata": {},
   "outputs": [],
   "source": [
    "ids = []\n",
    "scores = []\n",
    "comments = []\n",
    "def get_posts(items):\n",
    "    for i in range(0, len(items)):\n",
    "        posts = items[i]\n",
    "        for submission in range(0,len(posts)):\n",
    "            ids.append(posts[submission])\n",
    "            scores.append(reddit.submission(posts[submission]).score)\n",
    "            comments.append(reddit.submission(posts[submission]).num_comments)\n",
    "    return ids, scores, comments"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 29,
   "id": "19c14c8f-5cda-4563-ac5e-c7921131c0e0",
   "metadata": {},
   "outputs": [],
   "source": [
    "posts_df_40 = posts_df[3000:4000]\n",
    "\n",
    "chunks = [posts_df_40['id'][x:x+100] for x in range(0, len(posts_df_40), 100)]\n",
    "\n",
    "increments_40 = get_lists(chunks)\n",
    "\n",
    "get_posts(increments_40)\n",
    "\n",
    "scores_df_40 = pd.DataFrame([ids, scores, comments]).T\n",
    "\n",
    "scores_df_40.rename(columns={0:'id', 1:'score', 2:'comments'}, inplace=True)\n",
    "\n",
    "scores_df_40.to_csv('./Data/3_to_4k_scores.csv', index=False)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 30,
   "id": "06f05751-78ff-4535-b23f-6e218f46b5bd",
   "metadata": {},
   "outputs": [],
   "source": [
    "ids = []\n",
    "scores = []\n",
    "comments = []\n",
    "def get_posts(items):\n",
    "    for i in range(0, len(items)):\n",
    "        posts = items[i]\n",
    "        for submission in range(0,len(posts)):\n",
    "            ids.append(posts[submission])\n",
    "            scores.append(reddit.submission(posts[submission]).score)\n",
    "            comments.append(reddit.submission(posts[submission]).num_comments)\n",
    "    return ids, scores, comments"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 31,
   "id": "cdd7bf92-1817-4770-8708-14ce493649a0",
   "metadata": {},
   "outputs": [],
   "source": [
    "posts_df_50 = posts_df[4000:5000]\n",
    "\n",
    "chunks = [posts_df_50['id'][x:x+100] for x in range(0, len(posts_df_50), 100)]\n",
    "\n",
    "increments_50 = get_lists(chunks)\n",
    "\n",
    "get_posts(increments_50)\n",
    "\n",
    "scores_df_50 = pd.DataFrame([ids, scores, comments]).T\n",
    "\n",
    "scores_df_50.rename(columns={0:'id', 1:'score', 2:'comments'}, inplace=True)\n",
    "scores_df_50.to_csv('./Data/4_to_5k_scores.csv', index=False)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 32,
   "id": "86e84b25-38f8-4738-8cd0-13b526e7c966",
   "metadata": {},
   "outputs": [],
   "source": [
    "ids = []\n",
    "scores = []\n",
    "comments = []\n",
    "def get_posts(items):\n",
    "    for i in range(0, len(items)):\n",
    "        posts = items[i]\n",
    "        for submission in range(0,len(posts)):\n",
    "            ids.append(posts[submission])\n",
    "            scores.append(reddit.submission(posts[submission]).score)\n",
    "            comments.append(reddit.submission(posts[submission]).num_comments)\n",
    "    return ids, scores, comments"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 34,
   "id": "4c95dfbf-1838-4d57-b86c-9e927c287e3a",
   "metadata": {},
   "outputs": [],
   "source": [
    "posts_df_60 = posts_df[5000:6000]\n",
    "\n",
    "chunks = [posts_df_60['id'][x:x+100] for x in range(0, len(posts_df_60), 100)]\n",
    "\n",
    "increments_60 = get_lists(chunks)\n",
    "\n",
    "get_posts(increments_60)\n",
    "\n",
    "scores_df_60 = pd.DataFrame([ids, scores, comments]).T\n",
    "\n",
    "scores_df_60.rename(columns={0:'id', 1:'score', 2:'comments'}, inplace=True)\n",
    "scores_df_60.to_csv('./Data/5_to_6k_scores.csv', index=False)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 35,
   "id": "5d4befe0-d109-4be7-ad8e-fee00fd5ca68",
   "metadata": {},
   "outputs": [],
   "source": [
    "ids = []\n",
    "scores = []\n",
    "comments = []\n",
    "def get_posts(items):\n",
    "    for i in range(0, len(items)):\n",
    "        posts = items[i]\n",
    "        for submission in range(0,len(posts)):\n",
    "            ids.append(posts[submission])\n",
    "            scores.append(reddit.submission(posts[submission]).score)\n",
    "            comments.append(reddit.submission(posts[submission]).num_comments)\n",
    "    return ids, scores, comments"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 41,
   "id": "ddf90eb5-9318-44cd-bd71-0ae4f27a70fb",
   "metadata": {},
   "outputs": [],
   "source": [
    "posts_df_70 = posts_df[6000:7000]\n",
    "\n",
    "chunks = [posts_df_70['id'][x:x+100] for x in range(0, len(posts_df_70), 100)]\n",
    "\n",
    "increments_70 = get_lists(chunks)\n",
    "\n",
    "get_posts(increments_70)\n",
    "\n",
    "scores_df_70 = pd.DataFrame([ids, scores, comments]).T\n",
    "\n",
    "scores_df_70.rename(columns={0:'id', 1:'score', 2:'comments'}, inplace=True)\n",
    "scores_df_70.to_csv('./Data/7_to_7k_scores.csv', index=False)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 42,
   "id": "2ac20a87-09b8-4a34-9c27-7667f7468b49",
   "metadata": {},
   "outputs": [],
   "source": [
    "ids = []\n",
    "scores = []\n",
    "comments = []\n",
    "def get_posts(items):\n",
    "    for i in range(0, len(items)):\n",
    "        posts = items[i]\n",
    "        for submission in range(0,len(posts)):\n",
    "            ids.append(posts[submission])\n",
    "            scores.append(reddit.submission(posts[submission]).score)\n",
    "            comments.append(reddit.submission(posts[submission]).num_comments)\n",
    "    return ids, scores, comments"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 43,
   "id": "55fb7c7a-2026-44ae-a12d-6eda9e298ace",
   "metadata": {},
   "outputs": [],
   "source": [
    "posts_df_80 = posts_df[7000:8000]\n",
    "\n",
    "chunks = [posts_df_80['id'][x:x+100] for x in range(0, len(posts_df_80), 100)]\n",
    "\n",
    "increments_80 = get_lists(chunks)\n",
    "\n",
    "get_posts(increments_80)\n",
    "\n",
    "scores_df_80 = pd.DataFrame([ids, scores, comments]).T\n",
    "\n",
    "scores_df_80.rename(columns={0:'id', 1:'score', 2:'comments'}, inplace=True)\n",
    "scores_df_80.to_csv('./Data/7_to_8k_scores.csv', index=False)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 44,
   "id": "28ce3d2c-c9cf-402b-82da-7c73c435c2d2",
   "metadata": {},
   "outputs": [],
   "source": [
    "ids = []\n",
    "scores = []\n",
    "comments = []\n",
    "def get_posts(items):\n",
    "    for i in range(0, len(items)):\n",
    "        posts = items[i]\n",
    "        for submission in range(0,len(posts)):\n",
    "            ids.append(posts[submission])\n",
    "            scores.append(reddit.submission(posts[submission]).score)\n",
    "            comments.append(reddit.submission(posts[submission]).num_comments)\n",
    "    return ids, scores, comments"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 45,
   "id": "2b1cb8c4-56ce-422a-9622-fe8553927c27",
   "metadata": {},
   "outputs": [],
   "source": [
    "posts_df_90 = posts_df[8000:9000]\n",
    "\n",
    "chunks = [posts_df_90['id'][x:x+100] for x in range(0, len(posts_df_90), 100)]\n",
    "\n",
    "increments_90 = get_lists(chunks)\n",
    "\n",
    "get_posts(increments_90)\n",
    "\n",
    "scores_df_90 = pd.DataFrame([ids, scores, comments]).T\n",
    "\n",
    "scores_df_90.rename(columns={0:'id', 1:'score', 2:'comments'}, inplace=True)\n",
    "scores_df_90.to_csv('./Data/8_to_9k_scores.csv', index=False)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 46,
   "id": "c8d97257-4231-4f67-bb9f-ed2d0b46a271",
   "metadata": {},
   "outputs": [],
   "source": [
    "ids = []\n",
    "scores = []\n",
    "comments = []\n",
    "def get_posts(items):\n",
    "    for i in range(0, len(items)):\n",
    "        posts = items[i]\n",
    "        for submission in range(0,len(posts)):\n",
    "            ids.append(posts[submission])\n",
    "            scores.append(reddit.submission(posts[submission]).score)\n",
    "            comments.append(reddit.submission(posts[submission]).num_comments)\n",
    "    return ids, scores, comments"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 47,
   "id": "15aa1b77-2c20-4211-b94c-fcdc018ff2f5",
   "metadata": {},
   "outputs": [],
   "source": [
    "posts_df_100 = posts_df[9000:10001]\n",
    "\n",
    "chunks = [posts_df_100['id'][x:x+100] for x in range(0, len(posts_df_100), 100)]\n",
    "\n",
    "increments_100 = get_lists(chunks)\n",
    "\n",
    "get_posts(increments_100)\n",
    "\n",
    "scores_df_100 = pd.DataFrame([ids, scores, comments]).T\n",
    "\n",
    "scores_df_100.rename(columns={0:'id', 1:'score', 2:'comments'}, inplace=True)\n",
    "scores_df_100.to_csv('./Data/9_to_10k_scores.csv', index=False)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "d5d1fb23-d17c-4af2-ab17-96c0b27706a9",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.9.7"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
